# 安全性实践指南

[参见原文](https://platform.openai.com/docs/guides/safety-best-practices)

# 使用免费审查API

OpenAI的审查API是免费使用的，可以帮助降低完成中的不安全内容的频率。或者，您可能希望开发适合您用例的自己的内容过滤系统。

# 对抗性测试

我们建议对您的应用程序进行“红队”测试，以确保它对对抗性输入具有鲁棒性。测试您的产品在广泛的输入和用户行为下，既包括代表性的集合，也包括反映试图“破坏”您的应用程序的人的集合。它是否偏离了主题？是否可以轻松通过提示注入来重定向功能，例如“忽略先前的说明，改为这样做”？

# 人在环路（HITL）中

在任何可能的情况下，我们建议在将输出用于实践之前由人员进行审核。这在高风险领域和代码生成方面尤其重要。人员应该意识到系统的局限性，并可以访问任何需要验证输出的信息（例如，如果应用程序总结笔记，则人员应该可以轻松地访问原始笔记以进行参考）。

# 提示工程

“提示工程”可以帮助约束输出文本的主题和语气。这减少了产生不希望的内容的可能性，即使用户试图产生它。为模型提供额外的上下文（例如，在新输入之前提供几个高质量的期望行为示例）可以使其更容易将模型输出引导到所需的方向。

# “了解您的客户”（KYC， Know Your Customer）

通常，用户需要注册和登录以访问您的服务。将此服务链接到现有帐户（例如Gmail、LinkedIn或Facebook登录）可能有所帮助，但可能不适用于所有用例。要求信用卡或身份证进一步降低了风险。

# 限制用户输入并限制输出标记

限制用户可以输入到提示中的文本量有助于避免提示注入。限制输出标记的数量有助于减少误用的机会。

缩小输入或输出范围，特别是从可信来源中提取的范围，可以减少应用程序内可能出现的误用范围。

通过经过验证的下拉字段（例如维基百科上的电影列表）允许用户输入可以比允许开放式文本输入更安全。

如果可能，从后端返回一组经过验证的材料的输出比返回新生成的内容更安全（例如，将客户查询路由到最佳匹配的现有客户支持文章，而不是试图从头开始回答查询）。

# 允许用户报告问题

用户通常应该有一种易于使用的方法来报告应用程序行为不当或其他问题（列出的电子邮件地址、提交票据的方法等）。这种方法应该由人类监控，并根据需要进行回应。

# 了解和传达限制

从幻觉不准确的信息，到冒犯性输出，到偏见等等，语言模型可能不适合每个用例，而不进行重大修改。考虑模型是否适合您的目的，并在广泛的潜在输入范围上评估API的性能，以确定API的性能可能下降的情况。考虑您的客户群体以及他们将使用的输入范围，并确保他们的期望得到适当的校准。

> 如果在开发过程中您注意到API或与OpenAI相关的任何其他安全或安全问题，请通过[协调漏洞披露计划](https://openai.com/policies/coordinated-vulnerability-disclosure-policy)提交这些问题。
> 

# 终端用户ID

在您的请求中发送终端用户ID可以是帮助OpenAI监视和检测滥用的有用工具。这使OpenAI可以为您的团队提供更具操作性的反馈，以防我们检测到任何政策违规。

ID应该是一个唯一标识每个用户的字符串。我们建议对其用户名或电子邮件地址进行哈希处理，以避免向我们发送任何识别信息。如果您向非登录用户提供产品预览，可以发送会话ID。

您可以通过user参数在API请求中包含终端用户ID，如下所示：

```
response = openai.Completion.create(
  model="text-davinci-003",
  prompt="This is a test",
  max_tokens=5,
  user="user123456"
)

```