# 微调

<aside>
📖 **Fine tuning：** 微调，在已训练好的模型上继续训练，以提高性能和实现更准确的输出。在自然语言处理中，Fine-tuning使用预训练的语言模型为起点，然后微调以提高特定任务的性能。通过反向传播算法调整模型参数，Fine-tuning可以使输出更准确。此外，Fine-tuning还可以缩短训练时间和资源成本，更快地适应新任务和数据。

</aside>

## 可用模型

<aside>
🤖 微调目前仅适用于以下基础模型：**`davinci`**，**`curie`**，**`babbage`和`ada`**。
这些是原始模型，没有任何训练后的指令（例如`text-davinci-003`）。
您还可以[继续微调微调的模型](https://platform.openai.com/docs/guides/fine-tuning/continue-fine-tuning-from-a-fine-tuned-model)，以添加其他数据，而无需从头开始。

</aside>

## 训练数据

每个文件大小限制为最大 150 MB，组织在任何时候存储的文件总量限制为 1 GB。

<aside>
📖 **JSONL：**json lines，JSONL是一种用于存储和交换结构化数据的格式。它类似于JSON，但将每个JSON对象放在单独一行中。JSONL用于日志文件、机器学习数据集等场景，避免了处理大型JSON文件时的内存问题，同时也可以轻松地逐行解析数据。

**Prompt：**提示/输入提示/引导文本，在自然语言处理模型中，提示是为模型生成输出而提供的文本输入的一部分。提示通常包含一个或多个完整句子或问题，用于描述模型需要预测的文本的上下文。与传统的文本输入不同，提示只包含模型需要关注的信息，留下了空间来生成新的输出结果。提示可能包含类别、关键词或其他标签，以帮助模型生成响应。

**Completion：**完成/补全，自然语言处理中，语言模型可以自动生成段落、句子、短语、标签和标题。模型可以根据上下文推断正确的下一步输出。自动文本生成技术可用于电子邮件、搜索建议和文章的生成等，非常实用。

**Tokenizer：**分词器，将一段文本分割为单独的单词或标记的程序。其作用是将连续文本转换为单个单词，同时标记化文本以便于后续的文本处理。

</aside>

- 微调 OpenAI 模型时，使用一组训练示例。
    - 每个示例都包含单个输入（“提示”）及其相关的输出（“完成”）。
    - 每个提示应以固定的分隔符结尾，以便告知模型提示何时结束，完成何时开始。
    - 每个完成应以空格开头，这是由于我们的分词器将大多数单词标记化为前导空格。
    - 每个完成应以固定的停止序列结尾，以便告知模型何时完成。

<aside>
⚙ 一个通常有效的简单分隔符是 **`\\\\n\\\\n###\\\\n\\\\n`**，该分隔符不应出现在任何提示中。
停止序列可以是 **`\\\\n`**、**`###`** 或任何不出现在任何完成中的标记。

</aside>

- 用于推断时，应以与训练数据集相同的方式格式化提示，包括相同的分隔符。
    - 同时指定相同的停止序列以正确截断完成。

<aside>
⚠️ 确保用于微调的数据集在结构和任务类型上与模型将要用于的非常相似。
确保示例具有高质量，并遵循相同的期望格式

</aside>

## 特定情况参考

### 分类

<aside>
📖 **Classification：**分类，机器学习和人工智能领域中的术语，指分类任务。这是将输入的数据划分为不同类别或标签的过程。为此，我们需要训练分类器，以自动学习数据的特征。这通常需要选择适当的算法、特征和模型参数。
**Pre-defined classes：**预定义类别，在分类任务之前定义的标签，用于将输入数据分为不同的类别。分类器训练期间会指定预定义类别，分类器会自动学习每个类别与相应输入数据之间的关系，从而能够对新的输入数据进行分类。预定义类别可以是离散的或连续的，具体取决于任务需求和数据特征。
**Log probabilities：**对数概率，通过对分类模型分配给每个类别的概率值取自然对数，可以计算对数损失函数。这是一种优化技术，可以防止概率变得非常小甚至为零，从而导致数值不稳定。通过取对数，我们可以避免非常小的值，并更有效地执行算术计算。
**Logprobs：**对于分类模型分配给输入数据实例的一组预定义类别或标签的对数概率。具体而言，logprobs是在使用分类模型时可以指定的参数，用于获取将输入数据实例分配给每个预定义类别的对数概率。

</aside>

在分类问题中，每个输入都应该被分类到预定义的类别之一。

- 在提示的末尾使用分隔符，例如 **`\\n\\n###\\n\\n`**。在最终向模型发出请求时，也要附加此分隔符。
- 选择映射到单个token 的类。在推理时，指定 **`max_tokens=1`**，因为你只需要第一个 token 进行分类。
- 确保（提示 + 完成）不超过 2048 个 tokens，包括分隔符。
- 每个类别至少要有大约 100 个示例。
- 在使用模型时，可以指定 **`logprobs=5`**（对于 5 个类别）来获取类别的对数概率。

OpenAI官方提供了  [Tokenizer](https://platform.openai.com/tokenizer)  工具检测输入字符和token之间映射关系

### **条件生成**

<aside>
📖 Conditional generation：条件生成，一种需要给定某种输入就能生成内容的问题。这包括改写、摘要、实体提取、根据规格书编写产品描述、聊天机器人和许多其他问题。

</aside>

- 在提示的末尾使用分隔符，例如`\\n\\n###\\n\\n`。记得在最终向模型发送请求时也附加该分隔符。
- 在完成的末尾使用结束标记，例如`END`
- 记得在推理期间将结束标记添加为停止序列，例如`stop=[" END"]`
- 至少要有 ~500 个示例
- 确保（提示 + 完成）不超过 2048 个标记，包括分隔符

<aside>
⚙ 对于这些用例，使用较低的学习率和仅进行 1-2 次训练时往往效果更好。

</aside>

## 进阶用法

### 定制模型名称

使用suffix参数为微调模型名称添加最多**40个字符**的后缀。

OpenAI CLI:

```markdown
`openai api fine_tunes.create -t test.jsonl -m ada --suffix "custom model name"`
```

结果名称将为：

`ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`

**分析您的微调模型**

<aside>
📖 Event：事件/活动，任务相关的事件和活动，包括任务的进展和结果。例如，在语言模型的 fine-tune 任务中，"event"可以包括：

- 模型文件的上传和加载
- 训练周期数和学习率
- 每个周期的训练和验证损失
- 训练过程中的准确率和评估指标
- 训练过程的开始和结束时间
- 任务被暂停或重新启动的事件
- 最终结果文件的生成时间和 ID

查看这些事件，可更好地了解任务的进展和结果，进行调整和优化。

</aside>

一旦每个任务完成，结果文件将附加到每个任务上。

检索微调时，将列出此结果文件ID，查看微调的事件时也将列出此结果文件ID。

可以下载这些文件：

OpenAI CLI:

```markdown
openai api fine_tunes.results -i <YOUR_FINE_TUNE_JOB_ID>
```

CURL:

```markdown
curl <https://api.openai.com/v1/files/$RESULTS_FILE_ID/content> \\   -H "Authorization: Bearer $OPENAI_API_KEY" > results.csv
```

- `_results.csv`文件包含每个训练步骤的一行，其中一步骤是指对一批数据进行一次前向和后向传递。除了步骤编号外，每行包含以下与该步骤对应的字段：
- **elapsed_tokens**：模型到目前为止看到的标记数（包括重复）
- **elapsed_examples**：模型到目前为止看到的示例数（包括重复），其中一个示例是批处理中的一个元素。例如，如果`batch_size = 4`**，则每个步骤将使**`elapsed_examples`增加4。
- **training_loss**：训练批次上的损失
- **training_sequence_accuracy**：训练批次中**完成**的百分比，其中模型的预测标记与真实完成标记完全匹配。例如，如果您的数据包含完成[[1, 2]，[0, 5]，[4, 2]]，并且模型预测[[1, 1]，[0, 5]，[4, 2]]，则准确率将为2/3 = 0.67
- **training_token_accuracy**：模型正确预测的训练批次中的**标记**百分比。例如，如果您的数据包含完成[[1, 2]，[0, 5]，[4, 2]]，并且模型预测[[1, 1]，[0, 5]，[4, 2]]，则准确率将为5/6 = 0.83

### **分类特定**指标

<aside>
📖 **Specific metrics：**特定度量/指标，针对分类任务的性能指标。

**Multi-classes classification：**多类分类，将一组数据分配到多个预定义类别或标签中的分类任务。在这种问题中，每个数据点都有一个或多个标签，而这些标签是事先定义的类别。如果有n个预定义的类别，则一个多类分类问题就是将数据点分配到其中一个类别中。

**Binary classification：**二元分类，一种问题类型，其中只有两种可能的结果。例如垃圾邮件、欺诈和疾病诊断。模型将数据分配到“正面”或“负面”类别，或“1”或“0”。目标是基于其特征准确预测新数据点的标签。

**Accurancy：**准确率，一种常见的分类度量标准，用于衡量模型正确预测目标类别的频率。它的计算方法是将正确预测的数量除以总预测数量。

**Weighted F1 score：**加权 F1 得分，一种分类度量标准，它考虑了每个类别的精确度和召回率。它的计算方法是精确度和召回率的加权平均值，其中权重基于每个类别中的样本数量。F1 得分越高，模型的性能越好。

**Precision：**精度，是真正预测（TP）比上所有预测为正的结果（真正预测和假正预测，即TP /（TP + FP））的比例。它衡量了预测为正的实例中有多少实际为正的。高精度意味着模型的假阳性预测很少。

**Recall：**召回率，是真正预测（TP）比上所有实际正实例（真正预测和假负预测，即TP /（TP + FN））的比例。它衡量了模型能够识别出实际正实例的数量。高召回率意味着模型能够识别出大多数实际正实例。

**F_beta score：**F_beta分数，使用加权调和平均值将精度和召回率组合成一个单一的度量标准。它定义为（1 + beta ^ 2）精度召回率/（beta ^ 2 *精度+召回率）。beta参数控制精度和召回率之间的权衡，其中beta = 1对两个度量标准给予相等的权重。

**AUROC： Area Under the Receiver Operating Characteristic Curve**，接收器工作特征曲线下的面积，一种流行的分类度量标准，它汇总了在所有可能的分类阈值上真正预测率（TPR）和假正预测率（FPR）之间的权衡。它的取值范围从0.5（随机分类器）到1（完美分类器），取值越高表示性能越好。

**AUPRC： Area Under the Precision-Recall Curve，**精度-召回率曲线下的面积，一个度量标准，它汇总了在所有可能的分类阈值上精度和召回率之间的权衡。特别是当处理正类别稀有的不平衡数据集时非常有用。它的取值范围从0（最差）到1（最好），取值越高表示性能越好。

**True positive prediction：**真正预测，模型正确地预测样本属于正类的情况。在二元分类中，正类是模型试图预测或识别的类。

**False positive prediction：**假正预测，模型错误地将负样本识别为正样本。在二元分类中，假正预测是指模型错误地将实际上属于负类的样本，误分类为正类。

**False negative prediciton：**假负预测，模型将真实正例预测为负例，称为“误拒绝”或“假阴性”预测。在二元分类中，假负预测是将真实正例分类为负例的情况。

</aside>

要启用此选项，请设置参数`--compute_classification_metrics`

<aside>
⚠️ **必须提供一个验证文件**

</aside>

设置`classification_n_classes`参数进行**多类分类**

设置`classification_positive_class`参数进行**二元分类。**

OpenAI CLI：

```markdown
# For multiclass classification
openai api fine_tunes.create \
  -t <TRAIN_FILE_ID_OR_PATH> \
  -v <VALIDATION_FILE_OR_PATH> \
  -m <MODEL> \
  --compute_classification_metrics \
  --classification_n_classes <N_CLASSES>

# For binary classification
openai api fine_tunes.create \
  -t <TRAIN_FILE_ID_OR_PATH> \
  -v <VALIDATION_FILE_OR_PATH> \
  -m <MODEL> \
  --compute_classification_metrics \
  --classification_n_classes 2 \
  --classification_positive_class <POSITIVE_CLASS_FROM_DATASET>
```

### **对于多类分类**

- **classification/accuracy**：准确性
- **classification/weighted_f1_score**：加权F-1得分

### **对于二元分类**

以下指标基于分类阈值为0.5（即当概率> 0.5时，将示例分类为正类）。

- **classification/accuracy**
- **classification/precision**
- **classification/recall**
- **classification/f{beta}**
- **classification/auroc** - AUROC
- **classification/auprc** - AUPRC

请注意，这些评估假定您正在使用用于类的文本标签，这些标签会被分词成单个标记，如上所述。如果不符合这些条件，则您获得的数字可能不正确。

## **验证**

可以为验证保留一些数据。

验证文件与训练文件具有完全相同的格式，训练和验证数据应该是**互斥**的。

<aside>
📌 **互斥**意味着验证集和训练集不应分享任何数据。因为对两个集合使用相同的数据可能会导致模型存在偏差，从而导致验证准确性不准确。
拥有互斥的集合可以确保在验证期间使用新的未见过的数据来评估模型。

</aside>

如果在创建微调作业时包括验证文件，则生成的结果文件将包括评估微调模型在训练期间定期针对验证数据的表现的指标。

OpenAI CLI：

```markdown
openai api fine_tunes.create -t <TRAIN_FILE_ID_OR_PATH> \\   -v <VALIDATION_FILE_ID_OR_PATH> \\   -m <MODEL>
```

如果提供了验证文件，则我们会定期计算验证数据批次的指标。您将在结果文件中看到以下其他指标：

- **validation_loss**：验证批次上的损失
- **validation_sequence_accuracy**：验证批次中完成的百分比，其中模型的预测标记与真实完成标记完全匹配。例如，如果您的数据包含完成[[1, 2]，[0, 5]，[4, 2]]，并且模型预测[[1, 1]，[0, 5]，[4, 2]]，则准确率将为2/3 = 0.67
- **validation_token_accuracy**：模型正确预测的验证批次中的标记百分比。例如，如果您的数据包含完成[[1, 2]，[0, 5]，[4, 2]]，并且模型预测[[1, 1]，[0, 5]，[4, 2]]，则准确率将为5/6 = 0.83

## **超参数**

<aside>
💡 机器学习算法中的超参数在训练之前设置，会影响模型的学习过程和性能。它们与模型参数不同，模型参数是在训练期间学习的。

</aside>

OpenAI预先选择了适用于各种用例的默认超参数。唯一必需的参数是训练文件。

**调整用于微调的超参数通常会导致产生更高质量的输出模型。**

<aside>
📖 **Epoch：**训练轮次，在机器学习中，一个 epoch 是通过训练数据集的一次迭代，算法会根据损失更新参数。使用的 epoch 数量是一个优化性能的超参数。选择正确的数量对于防止欠拟合或过拟合非常关键，当模型无法学习模式或变得过于专业化时会发生这种情况。因此，应仔细选择 epoch 的数量以获得最佳性能。

**Batch size：**批处理大小/批量大小，模型训练的样本数取决于数据集大小和计算资源。较小的批处理大小可加快模型收敛速度，但可能影响模型性能；较大的批处理大小可提高梯度稳定性，但需要更多计算资源，可能收敛速度变慢和难以处理大量特征的数据。因此，需根据具体情况选择适当批处理大小。

**Learning rate：**学习率，控制模型在训练过程中对参数的调整程度。学习率决定了每一步移动的步长大小。选择适当的学习率非常重要。常用的学习率选择范围为 0.0001 至 1.0，具体选择取决于模型架构和数据集特点。

**Batch processing：**批处理，训练模型的一种方法是将数据分为批次，输入到模型中计算损失函数并反向传播计算梯度来更新模型参数。这称为“批次训练”。批次训练比全数据集训练更有效，可以减少计算和内存消耗，提高模型泛化能力，降低过拟合的风险。批次训练还可以并行处理，加快训练速度，缩短训练时间。

**Underfitting：**欠拟合，指模型无法充分学习训练数据中的特征和规律，因而在训练集和测试集上的表现都不好。这意味着模型的拟合程度较低，其预测能力较弱，可能需要更复杂的模型来提高准确性。

**Overfitting：**过拟合，指模型过度学习训练数据中的特征和规律，导致在训练集上表现良好，但在测试集等新的数据上表现较差。这意味着模型过于专业化于训练数据，泛化能力较差，可能需要更少的特征、更多的数据或正则化来减少过度拟合。

</aside>

可能需要配置以下内容：

- **`model`**：要微调的基础模型的名称。可以选择“ada”，“babbage”，“curie”或“davinci”。有关这些模型的更多信息，请参见[模型](https://platform.openai.com/docs/models)文档。
- **`n_epochs`** - 默认为4。训练模型的时期数。时期指的是对训练数据集的完整循环。
- **`batch_size`** - 默认为训练集中示例数量的约0.2％，上限为256。批处理大小是用于训练单个前向和后向传递的训练示例数。一般来说，我们发现较大的批处理大小对于较大的数据集效果更好。
- **`learning_rate_multiplier`** - 默认值为0.05，0.1或0.2，具体取决于最终的`batch_size`。微调学习率是用于预训练的原始学习率乘以此乘数。建议尝试在0.02到0.2范围内的值，以查看哪些值会产生最佳结果。**较大的学习率通常在使用较大的批处理大小时表现更好**。
- **`compute_classification_metrics`** - 默认为False。如果为True，则为分类任务进行微调时，在验证集上计算分类特定指标（准确性，F-1得分等），并在每个时期结束时计算。

```markdown
要通过OpenAI CLI传递这些其他超参数，请使用命令行标志，例如：
openai api fine_tunes.create \\   -t file-JD89ePi5KMsB3Tayeli5ovfW \\   -m ada \\   --n_epochs 1
```

**从微调模型继续微调**

如果已经为任务微调了模型，并且现在有其他训练数据需要合并，可以从模型中继续微调。

这样可以创建一个模型，该模型已经从所有训练数据中学习，而无需从头开始重新训练。

要执行此操作，请在创建新的微调作业时传入微调模型名称（例如`-m curie:ft-<org>-<date>`**）。**

<aside>
⚙ 其他培训参数不必更改，但是如果新训练数据比以前的培训数据小得多，则可以将`learning_rate_multiplier`减少2到4倍。

</aside>